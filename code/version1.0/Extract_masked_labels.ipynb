{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "from torchvision import transforms, utils, datasets\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler, WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open the file and extract the labels of the imagenet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_label_list = pd.read_csv(r\"/home/junzhin/Project/Summer_project/code/version1.0/imagenet_labels_set.txt\", sep = \" \",header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_label_list_dict = dict(zip(imagenet_label_list[2].apply(lambda x: x.lower()), imagenet_label_list[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Checking the directory of the imagenet and make sure the existence and presence of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['face_annotations_ILSVRC.json', 'train_blurred', 'val_blurred']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "your_path =r\"/data/gpfs/datasets/Imagenet/\" \n",
    "file_dir = os.listdir(your_path)\n",
    "file_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "train_filenames = os.listdir(your_path + file_dir[1])\n",
    "valid_filenames = os.listdir(your_path + file_dir[2])\n",
    "print(len(train_filenames))\n",
    "print(len(valid_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(set(train_filenames) == set(valid_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_training_filePath = os.path.join(your_path, file_dir[1])\n",
    "imagenet_valid_filePath = os.path.join(your_path, file_dir[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_net_train_dataset = datasets.ImageFolder(\n",
    "        imagenet_training_filePath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open the office31 dataset and extract the labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amazon', 'dslr', 'webcam']\n"
     ]
    }
   ],
   "source": [
    "office31_path =r\"/home/junzhin/Project/datasets/domain_adaptation_images/\"\n",
    "office31_dir = os.listdir(office31_path)\n",
    "amazon_file_path = os.path.join(office31_path, office31_dir[0]+ \"/images/\")\n",
    "dslr_file_path = os.path.join(office31_path, office31_dir[1]+ \"/images/\")\n",
    "webcam_file_path = os.path.join(office31_path, office31_dir[2]+ \"/images/\")\n",
    "print(office31_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking if three domains have the same set of class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon =  os.listdir(amazon_file_path)\n",
    "dslr =  os.listdir(dslr_file_path)\n",
    "webcam =  os.listdir(webcam_file_path)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(set(amazon) == set(dslr) == set(webcam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading one of the domains of the class labels for further manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 2817\n",
       "    Root location: /home/junzhin/Project/datasets/domain_adaptation_images/amazon/images/"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "office_31_train_dataset = datasets.ImageFolder(\n",
    "        amazon_file_path)\n",
    "office_31_train_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 92, 1: 82, 2: 72, 3: 82, 4: 36, 5: 94, 6: 91, 7: 97, 8: 97, 9: 81, 10: 99, 11: 100, 12: 100, 13: 98, 14: 100, 15: 99, 16: 100, 17: 94, 18: 96, 19: 95, 20: 93, 21: 100, 22: 98, 23: 98, 24: 90, 25: 75, 26: 100, 27: 99, 28: 99, 29: 96, 30: 64}\n",
      "['back_pack', 'bike', 'bike_helmet', 'bookcase', 'bottle', 'calculator', 'desk_chair', 'desk_lamp', 'desktop_computer', 'file_cabinet', 'headphones', 'keyboard', 'laptop_computer', 'letter_tray', 'mobile_phone', 'monitor', 'mouse', 'mug', 'paper_notebook', 'pen']\n"
     ]
    }
   ],
   "source": [
    "print(dict(Counter(office_31_train_dataset.targets)))\n",
    "office_31_training_labels = office_31_train_dataset.classes\n",
    "print(office_31_train_dataset.classes[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "selected_index = [ office_31_train_dataset.class_to_idx[i] for i in office_31_train_dataset.classes[:20]]\n",
    "print(selected_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_1 = torch.utils.data.Subset(office_31_train_dataset, selected_index)\n",
    "train_loader = torch.utils.data.DataLoader(trainset_1, batch_size=1, shuffle= False, num_workers=1, pin_memory=True,sampler=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the duplicate classes between the imagenet of 1000 classes and office31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "office_31_training_labels = [word.lower().replace(\"_\", \" \") for word in office_31_training_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_label_list = [word.lower().replace(\"_\", \" \") for word in imagenet_label_list[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Exact string match between two datasets classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_list1 = set(office_31_training_labels).intersection(set(imagenet_label_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2 Similarity string matching between two datasets classes: To remove any possible similar strings in both set of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similars_dict(source_labels, target_labels, threshold = 1.0):\n",
    "    similarity_dict =  {}\n",
    "    threshold = 1.0\n",
    "    for x in source_labels:\n",
    "        similarity_dict[x] = []\n",
    "        for y in target_labels:\n",
    "            similarity_score = textdistance.smith_waterman.normalized_similarity(x,y)\n",
    "            if similarity_score >= threshold:\n",
    "                similarity_dict[x].append([y,similarity_score])\n",
    "    for each_word_list in similarity_dict:\n",
    "        similarity_dict[each_word_list].sort(key=lambda x: x[1], reverse = True)\n",
    "    # levenshtein damerau_levenshtein gotoh smith_waterman\n",
    "    return similarity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_dict = find_similars_dict(office_31_training_labels,imagenet_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'back pack': [], 'bike': [['mountain bike', 1.0]], 'bike helmet': [], 'bookcase': [['bookcase', 1.0]], 'bottle': [['beer bottle', 1.0], ['pop bottle', 1.0], ['wine bottle', 1.0], ['pill bottle', 1.0], ['water bottle', 1.0]], 'calculator': [], 'desk chair': [], 'desk lamp': [], 'desktop computer': [['desktop computer', 1.0]], 'file cabinet': [], 'headphones': [], 'keyboard': [['computer keyboard', 1.0], ['typewriter keyboard', 1.0]], 'laptop computer': [], 'letter tray': [['tray', 1.0]], 'mobile phone': [], 'monitor': [['monitor', 1.0]], 'mouse': [['mouse', 1.0]], 'mug': [['coffee mug', 1.0]], 'paper notebook': [['notebook', 1.0]], 'pen': [['fountain pen', 1.0]], 'phone': [['microphone', 1.0], ['pay-phone', 1.0], ['cellular telephone', 1.0], ['dial telephone', 1.0]], 'printer': [['printer', 1.0]], 'projector': [['projector', 1.0]], 'punchers': [], 'ring binder': [['binder', 1.0]], 'ruler': [], 'scissors': [], 'speaker': [['loudspeaker', 1.0]], 'stapler': [], 'tape dispenser': [], 'trash can': []}\n"
     ]
    }
   ],
   "source": [
    "print(similarity_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cellular telephone', 'fountain pen', 'desktop computer', 'tray', 'microphone', 'pay-phone', 'mountain bike', 'computer keyboard', 'dial telephone', 'coffee mug', 'pill bottle', 'printer', 'projector', 'binder', 'typewriter keyboard', 'monitor', 'bookcase', 'pop bottle', 'mouse', 'wine bottle', 'loudspeaker', 'beer bottle', 'notebook', 'water bottle'}\n"
     ]
    }
   ],
   "source": [
    "masked_list2 = set()\n",
    "for key in similarity_dict:\n",
    "    for values in similarity_dict[key]:\n",
    "        masked_list2.add(values[0])\n",
    "print(masked_list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save them into files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bookcase', 'desktop_computer', 'mouse', 'printer', 'projector', 'monitor']\n",
      "['cellular_telephone', 'fountain_pen', 'desktop_computer', 'tray', 'microphone', 'pay-phone', 'mountain_bike', 'computer_keyboard', 'dial_telephone', 'coffee_mug', 'pill_bottle', 'printer', 'projector', 'binder', 'typewriter_keyboard', 'monitor', 'bookcase', 'pop_bottle', 'mouse', 'wine_bottle', 'loudspeaker', 'beer_bottle', 'notebook', 'water_bottle']\n"
     ]
    }
   ],
   "source": [
    "masked_list1 = [x.replace(\" \", \"_\") for x in masked_list1]\n",
    "masked_list2 = [x.replace(\" \", \"_\") for x in masked_list2]\n",
    "print(masked_list1)\n",
    "print(masked_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_list1_df = pd.DataFrame([(imagenet_label_list_dict[i], i) for i in masked_list1])\n",
    "masked_list2_df = pd.DataFrame([(imagenet_label_list_dict[i], i) for i in masked_list2])\n",
    "masked_list1_df.to_csv('masked_office31_imagenetlabel1_df.csv',index = False, header = False)\n",
    "masked_list2_df.to_csv('masked_office31_imagenetlabel2_df.csv',index = False, header = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open the officehome dataset and extract the labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "officehome_path =r\"/home/junzhin/Project/datasets/OfficeHomeDataset_10072016\"\n",
    "officehome_dir = os.listdir(officehome_path)\n",
    "art_file_path = os.path.join(officehome_path, officehome_dir[0])\n",
    "clipart_file_path = os.path.join(officehome_path, officehome_dir[1])\n",
    "product_file_path = os.path.join(officehome_path, officehome_dir[4])\n",
    "world_file_path = os.path.join(officehome_path, officehome_dir[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/junzhin/Project/datasets/OfficeHomeDataset_10072016\n",
      "['Art', 'Clipart', 'ImageInfo.csv', 'imagelist.txt', 'Product', 'Real World']\n"
     ]
    }
   ],
   "source": [
    "print(officehome_path)\n",
    "print(officehome_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "art =  os.listdir(art_file_path)\n",
    "clipart =  os.listdir(clipart_file_path)\n",
    "product =  os.listdir(product_file_path)\n",
    "world =  os.listdir(world_file_path)\n",
    "print(set(art) == set(clipart) == set(product) == set(world))\n",
    "print(len(set(art)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing one of the domains for labels extractions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "office_home_train_dataset = datasets.ImageFolder(art_file_path)\n",
    "office_home_train_dataset.classes\n",
    "office_home_label_list = [i.lower().replace(\"_\", \" \") for i in office_home_train_dataset.classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'backpack',\n",
       " 'bucket',\n",
       " 'hammer',\n",
       " 'laptop',\n",
       " 'monitor',\n",
       " 'mouse',\n",
       " 'notebook',\n",
       " 'printer',\n",
       " 'radio',\n",
       " 'refrigerator',\n",
       " 'screwdriver'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_list1 = set(office_home_label_list).intersection(set(imagenet_label_list))\n",
    "masked_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_dict = find_similars_dict(office_home_label_list, imagenet_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alarm clock': [], 'backpack': [['backpack', 1.0]], 'batteries': [], 'bed': [], 'bike': [['mountain bike', 1.0]], 'bottle': [['beer bottle', 1.0], ['pop bottle', 1.0], ['wine bottle', 1.0], ['pill bottle', 1.0], ['water bottle', 1.0]], 'bucket': [['bucket', 1.0]], 'calculator': [], 'calendar': [], 'candles': [], 'chair': [['barber chair', 1.0], ['folding chair', 1.0], ['rocking chair', 1.0]], 'clipboards': [], 'computer': [['desktop computer', 1.0], ['hand-held computer', 1.0]], 'couch': [['studio couch', 1.0]], 'curtains': [], 'desk lamp': [], 'drill': [['power drill', 1.0]], 'eraser': [['rubber eraser', 1.0]], 'exit sign': [], 'fan': [['electric fan', 1.0]], 'file cabinet': [], 'flipflops': [], 'flowers': [], 'folder': [], 'fork': [], 'glasses': [['sunglasses', 1.0]], 'hammer': [['hammer', 1.0]], 'helmet': [['crash helmet', 1.0], ['football helmet', 1.0]], 'kettle': [], 'keyboard': [['computer keyboard', 1.0], ['typewriter keyboard', 1.0]], 'knives': [], 'lamp shade': [], 'laptop': [['laptop', 1.0]], 'marker': [], 'monitor': [['monitor', 1.0]], 'mop': [], 'mouse': [['mouse', 1.0]], 'mug': [['coffee mug', 1.0]], 'notebook': [['notebook', 1.0]], 'oven': [['dutch oven', 1.0]], 'pan': [['frying pan', 1.0]], 'paper clip': [], 'pen': [['fountain pen', 1.0]], 'pencil': [], 'postit notes': [], 'printer': [['printer', 1.0]], 'push pin': [], 'radio': [['radio', 1.0]], 'refrigerator': [['refrigerator', 1.0]], 'ruler': [], 'scissors': [], 'screwdriver': [['screwdriver', 1.0]], 'shelf': [], 'sink': [], 'sneakers': [], 'soda': [], 'speaker': [['loudspeaker', 1.0]], 'spoon': [['wooden spoon', 1.0]], 'tv': [], 'table': [['pool table', 1.0], ['dining table', 1.0]], 'telephone': [['cellular telephone', 1.0], ['dial telephone', 1.0]], 'toothbrush': [], 'toys': [], 'trash can': [], 'webcam': []}\n"
     ]
    }
   ],
   "source": [
    "print(similarity_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cellular telephone', 'rubber eraser', 'fountain pen', 'desktop computer', 'laptop', 'football helmet', 'rocking chair', 'mountain bike', 'computer keyboard', 'dial telephone', 'screwdriver', 'barber chair', 'coffee mug', 'dining table', 'pill bottle', 'crash helmet', 'electric fan', 'printer', 'pool table', 'folding chair', 'power drill', 'hand-held computer', 'wooden spoon', 'radio', 'refrigerator', 'studio couch', 'backpack', 'typewriter keyboard', 'bucket', 'monitor', 'dutch oven', 'pop bottle', 'hammer', 'mouse', 'frying pan', 'wine bottle', 'loudspeaker', 'beer bottle', 'notebook', 'sunglasses', 'water bottle'}\n"
     ]
    }
   ],
   "source": [
    "masked_list2 = set()\n",
    "for key in similarity_dict:\n",
    "    for values in similarity_dict[key]:\n",
    "        masked_list2.add(values[0])\n",
    "print(masked_list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save them into files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hammer', 'mouse', 'radio', 'laptop', 'printer', 'notebook', 'refrigerator', 'screwdriver', 'backpack', 'bucket', 'monitor']\n",
      "['cellular_telephone', 'rubber_eraser', 'fountain_pen', 'desktop_computer', 'laptop', 'football_helmet', 'rocking_chair', 'mountain_bike', 'computer_keyboard', 'dial_telephone', 'screwdriver', 'barber_chair', 'coffee_mug', 'dining_table', 'pill_bottle', 'crash_helmet', 'electric_fan', 'printer', 'pool_table', 'folding_chair', 'power_drill', 'hand-held_computer', 'wooden_spoon', 'radio', 'refrigerator', 'studio_couch', 'backpack', 'typewriter_keyboard', 'bucket', 'monitor', 'dutch_oven', 'pop_bottle', 'hammer', 'mouse', 'frying_pan', 'wine_bottle', 'loudspeaker', 'beer_bottle', 'notebook', 'sunglasses', 'water_bottle']\n"
     ]
    }
   ],
   "source": [
    "masked_list1 = [x.replace(\" \", \"_\") for x in masked_list1]\n",
    "masked_list2 = [x.replace(\" \", \"_\") for x in masked_list2]\n",
    "print(masked_list1)\n",
    "print(masked_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_list1_df = pd.DataFrame([(imagenet_label_list_dict[i], i) for i in masked_list1])\n",
    "masked_list2_df = pd.DataFrame([(imagenet_label_list_dict[i], i) for i in masked_list2])\n",
    "masked_list1_df.to_csv('masked_officehome_imagenetlabel1_df.csv',index = False, header = False)\n",
    "masked_list2_df.to_csv('masked_officehome_imagenetlabel2_df.csv',index = False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment of choosing the subset of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 1281066\n",
      "    Root location: /data/gpfs/datasets/Imagenet/train_blurred\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 49997\n",
      "    Root location: /data/gpfs/datasets/Imagenet/val_blurred\n"
     ]
    }
   ],
   "source": [
    "image_net_train_dataset = datasets.ImageFolder(\n",
    "        imagenet_training_filePath)\n",
    "print(image_net_train_dataset)\n",
    "\n",
    "\n",
    "\n",
    "image_net_valid_dataset = datasets.ImageFolder(\n",
    "        imagenet_valid_filePath)\n",
    "print(image_net_valid_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_label_list_office31 = pd.read_csv(r\"/home/junzhin/Project/Summer_project/code/version1.0/masked_office31_imagenetlabel2_df.csv\", header = None)\n",
    "masked_label_list_officehome = pd.read_csv(r\"/home/junzhin/Project/Summer_project/code/version1.0/masked_officehome_imagenetlabel2_df.csv\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "976\n",
      "959\n"
     ]
    }
   ],
   "source": [
    "chosen_index_office31 = [image_net_train_dataset.class_to_idx[i] for i in image_net_train_dataset.classes if i not in list(masked_label_list_office31[0])]\n",
    "print(len(chosen_index_office31))\n",
    "chosen_index_officehome = [image_net_train_dataset.class_to_idx[i]  for i in image_net_train_dataset.classes if i not in list(masked_label_list_officehome[0])]\n",
    "print(len(chosen_index_officehome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_image_net_train_dataset_office31 = torch.utils.data.Subset(image_net_train_dataset, chosen_index_office31)\n",
    "masked_image_net_train_dataset_officehome = torch.utils.data.Subset(image_net_train_dataset, chosen_index_officehome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "976\n"
     ]
    }
   ],
   "source": [
    "print(len(masked_image_net_train_dataset_office31))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "976\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(masked_image_net_train_dataset_office31, batch_size=1, shuffle=False, pin_memory=True)\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "x = torch.arange(-5, 5, 0.1).view(-1, 1)\n",
    "y = -5 * x + 0.1 * torch.randn(x.size())\n",
    "\n",
    "model = torch.nn.Linear(1, 1)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
    "\n",
    "def train_model(iter):\n",
    "    for epoch in range(iter):\n",
    "        y1 = model(x)\n",
    "        loss = criterion(y1, y)\n",
    "        writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "train_model(10)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "for n_iter in range(100):\n",
    "    writer.add_scalar('Loss/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Loss/test', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/test', np.random.random(), n_iter)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "519dc1f00dacae036a835ca12c4661958509fbd43f895bd5282c37997e841633"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
