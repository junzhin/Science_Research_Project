Namespace(arch='alexnet', batch_size=32, bottleneck_dim=256, center_crop=False, data='Office31', data_processing='ours', epochs=30, iters_per_epoch=1000, local=True, local_pretrained_path='/home/junzhin/Project/Summer_project/code/version1.0/pretrained_model_results/AlEX_office31masked1_newmodel_best.pth.tar', log='/home/junzhin/Project/Summer_project/code/version2.0/training_results/dann/AlEX_office31masked1/A_D', lr=0.01, lr_decay=0.75, lr_gamma=0.001, momentum=0.9, per_class_eval=False, phase='train', pretrained=True, print_freq=50, root='/home/junzhin/Project/Summer_project/code/version2.0/data/office31', seed=1, source='A', target='D', trade_off=1.0, weight_decay=0.001, workers=2)
../../../../dann_modified.py:46: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using pre-trained model 'alexnet'
Epoch: [0][   0/1000]	Time  0.25 ( 0.25)	Data  0.03 ( 0.03)	Loss   4.17 (  4.17)	Cls Acc 9.4 (9.4)	Domain Acc 17.2 (17.2)
Epoch: [0][  50/1000]	Time  0.07 ( 0.37)	Data  0.05 ( 0.35)	Loss   3.19 (  3.36)	Cls Acc 15.6 (11.4)	Domain Acc 98.4 (94.4)
Epoch: [0][ 100/1000]	Time  0.66 ( 0.39)	Data  0.64 ( 0.37)	Loss   2.61 (  3.15)	Cls Acc 25.0 (15.8)	Domain Acc 95.3 (94.7)
Epoch: [0][ 150/1000]	Time  0.91 ( 0.40)	Data  0.89 ( 0.37)	Loss   2.61 (  2.98)	Cls Acc 28.1 (20.6)	Domain Acc 93.8 (94.5)
Traceback (most recent call last):
  File "../../../../dann_modified.py", line 405, in <module>
    main(args)
  File "../../../../dann_modified.py", line 152, in main
    lr_scheduler, epoch, args)
  File "../../../../dann_modified.py", line 223, in train
    transfer_loss = domain_adv(f_s, f_t)
  File "/home/junzhin/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/junzhin/Project/Summer_project/code/version2.0/dalib/adaptation/dann.py", line 69, in forward
    d_label_s = torch.ones((f_s.size(0), 1)).to(f_s.device)
KeyboardInterrupt
