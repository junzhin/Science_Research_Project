Namespace(arch='resnet18', batch_size=256, bottleneck_dim=256, center_crop=False, data='Office31', data_processing='ours', epochs=50, iters_per_epoch=1000, local=True, local_pretrained_path='/home/junzhin/Project/Summer_project/code/version1.0/pretrained_model_results/Resnet18_office31masked1_newcheckpoint.pth.tar', log='/home/junzhin/Project/Summer_project/code/version2.0/training_results/dann/Resnet18_office31masked1/A_D', lr=0.01, lr_decay=0.75, lr_gamma=0.001, momentum=0.9, per_class_eval=False, phase='train', pretrained=True, print_freq=50, root='/home/junzhin/Project/Summer_project/code/version2.0/data/office31', seed=1, source='A', target='D', trade_off=1.0, weight_decay=0.001, workers=4)
../../../../dann_modified.py:46: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using pre-trained model 'resnet18'
Traceback (most recent call last):
  File "../../../../dann_modified.py", line 405, in <module>
    main(args)
  File "../../../../dann_modified.py", line 152, in main
    lr_scheduler, epoch, args)
  File "../../../../dann_modified.py", line 239, in train
    loss.backward()
  File "/home/junzhin/anaconda3/lib/python3.7/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/junzhin/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py", line 156, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 11.91 GiB total capacity; 10.98 GiB already allocated; 45.25 MiB free; 10.99 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
