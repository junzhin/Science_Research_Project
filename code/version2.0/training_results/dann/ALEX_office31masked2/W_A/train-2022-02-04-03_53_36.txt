Namespace(arch='alexnet', batch_size=256, bottleneck_dim=256, center_crop=False, data='Office31', data_processing='ours', epochs=50, iters_per_epoch=1000, local=True, local_pretrained_path='/home/junzhin/Project/Summer_project/code/version1.0/pretrained_model_results/ALEX_office31masked2_newmodel_best.pth.tar', log='/home/junzhin/Project/Summer_project/code/version2.0/training_results/dann/ALEX_office31masked2/W_A', lr=0.01, lr_decay=0.75, lr_gamma=0.001, momentum=0.9, per_class_eval=False, phase='train', pretrained=True, print_freq=50, root='/home/junzhin/Project/Summer_project/code/version2.0/data/office31', seed=1, source='W', target='A', trade_off=1.0, weight_decay=0.001, workers=4)
../../../../dann_modified.py:46: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using pre-trained model 'alexnet'
Loading the local alexnet pretrained model weights!
Epoch: [0][   0/1000]	Time  0.90 ( 0.90)	Data  0.56 ( 0.56)	Loss   4.15 (  4.15)	Cls Acc 5.5 (5.5)	Domain Acc 62.1 (62.1)
Epoch: [0][  50/1000]	Time  0.50 ( 1.42)	Data  0.39 ( 1.30)	Loss   1.55 (  2.50)	Cls Acc 65.2 (41.7)	Domain Acc 95.1 (90.5)
Epoch: [0][ 100/1000]	Time  0.50 ( 1.45)	Data  0.39 ( 1.34)	Loss   0.67 (  1.80)	Cls Acc 93.0 (60.6)	Domain Acc 96.9 (93.2)
Epoch: [0][ 150/1000]	Time  2.65 ( 1.46)	Data  2.54 ( 1.34)	Loss   0.39 (  1.36)	Cls Acc 94.9 (72.1)	Domain Acc 97.7 (94.7)
Epoch: [0][ 200/1000]	Time  0.51 ( 1.45)	Data  0.39 ( 1.34)	Loss   0.59 (  1.11)	Cls Acc 99.2 (78.7)	Domain Acc 83.4 (94.8)
Epoch: [0][ 250/1000]	Time  0.50 ( 1.46)	Data  0.39 ( 1.34)	Loss   0.47 (  1.03)	Cls Acc 99.6 (82.8)	Domain Acc 85.9 (92.3)
Epoch: [0][ 300/1000]	Time  3.67 ( 1.46)	Data  3.55 ( 1.35)	Loss   1.23 (  0.95)	Cls Acc 100.0 (85.6)	Domain Acc 63.3 (90.5)
Epoch: [0][ 350/1000]	Time  0.50 ( 1.45)	Data  0.39 ( 1.34)	Loss   0.36 (  0.91)	Cls Acc 100.0 (87.6)	Domain Acc 88.3 (88.9)
Epoch: [0][ 400/1000]	Time  0.50 ( 1.46)	Data  0.39 ( 1.35)	Loss   0.94 (  0.88)	Cls Acc 100.0 (89.1)	Domain Acc 67.8 (87.4)
Epoch: [0][ 450/1000]	Time  2.79 ( 1.46)	Data  2.68 ( 1.35)	Loss   1.70 (  0.88)	Cls Acc 99.2 (90.3)	Domain Acc 52.0 (85.3)
Epoch: [0][ 500/1000]	Time  0.50 ( 1.46)	Data  0.39 ( 1.35)	Loss   2.09 (  0.94)	Cls Acc 98.4 (91.1)	Domain Acc 49.4 (82.0)
Epoch: [0][ 550/1000]	Time  2.15 ( 1.46)	Data  2.03 ( 1.35)	Loss   0.83 (  0.96)	Cls Acc 99.6 (91.9)	Domain Acc 63.7 (79.6)
Epoch: [0][ 600/1000]	Time  2.62 ( 1.46)	Data  2.51 ( 1.35)	Loss   1.07 (  0.96)	Cls Acc 99.6 (92.5)	Domain Acc 48.2 (77.7)
Epoch: [0][ 650/1000]	Time  0.49 ( 1.46)	Data  0.38 ( 1.35)	Loss   0.92 (  0.96)	Cls Acc 100.0 (93.0)	Domain Acc 52.5 (75.8)
Epoch: [0][ 700/1000]	Time  0.50 ( 1.46)	Data  0.38 ( 1.35)	Loss   0.97 (  0.95)	Cls Acc 100.0 (93.5)	Domain Acc 45.3 (74.1)
Epoch: [0][ 750/1000]	Time  3.37 ( 1.47)	Data  3.25 ( 1.35)	Loss   0.87 (  0.95)	Cls Acc 99.6 (93.9)	Domain Acc 50.8 (72.7)
Epoch: [0][ 800/1000]	Time  0.50 ( 1.46)	Data  0.39 ( 1.35)	Loss   0.82 (  0.95)	Cls Acc 99.2 (94.3)	Domain Acc 61.9 (71.3)
Epoch: [0][ 850/1000]	Time  0.49 ( 1.46)	Data  0.37 ( 1.35)	Loss   0.75 (  0.95)	Cls Acc 100.0 (94.6)	Domain Acc 58.4 (70.2)
Epoch: [0][ 900/1000]	Time  2.66 ( 1.46)	Data  2.54 ( 1.35)	Loss   0.94 (  0.94)	Cls Acc 100.0 (94.9)	Domain Acc 47.7 (69.2)
