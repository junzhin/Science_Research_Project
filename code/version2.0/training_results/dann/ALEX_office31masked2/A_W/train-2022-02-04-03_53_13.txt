Namespace(arch='alexnet', batch_size=256, bottleneck_dim=256, center_crop=False, data='Office31', data_processing='ours', epochs=50, iters_per_epoch=1000, local=True, local_pretrained_path='/home/junzhin/Project/Summer_project/code/version1.0/pretrained_model_results/ALEX_office31masked2_newmodel_best.pth.tar', log='/home/junzhin/Project/Summer_project/code/version2.0/training_results/dann/ALEX_office31masked2/A_W', lr=0.01, lr_decay=0.75, lr_gamma=0.001, momentum=0.9, per_class_eval=False, phase='train', pretrained=True, print_freq=50, root='/home/junzhin/Project/Summer_project/code/version2.0/data/office31', seed=1, source='A', target='W', trade_off=1.0, weight_decay=0.001, workers=4)
../../../../dann_modified.py:46: UserWarning: You have chosen to seed training. This will turn on the CUDNN deterministic setting, which can slow down your training considerably! You may see unexpected behavior when restarting from checkpoints.
  warnings.warn('You have chosen to seed training. '
=> using pre-trained model 'alexnet'
Loading the local alexnet pretrained model weights!
Epoch: [0][   0/1000]	Time  1.47 ( 1.47)	Data  1.15 ( 1.15)	Loss   4.22 (  4.22)	Cls Acc 3.5 (3.5)	Domain Acc 40.6 (40.6)
Epoch: [0][  50/1000]	Time  0.50 ( 1.42)	Data  0.39 ( 1.30)	Loss   2.65 (  3.05)	Cls Acc 28.9 (23.9)	Domain Acc 94.3 (90.0)
Epoch: [0][ 100/1000]	Time  0.49 ( 1.46)	Data  0.38 ( 1.35)	Loss   2.03 (  2.64)	Cls Acc 48.0 (34.0)	Domain Acc 96.1 (92.8)
Epoch: [0][ 150/1000]	Time  2.70 ( 1.46)	Data  2.59 ( 1.35)	Loss   1.75 (  2.36)	Cls Acc 53.9 (40.8)	Domain Acc 96.5 (94.0)
Epoch: [0][ 200/1000]	Time  0.51 ( 1.46)	Data  0.40 ( 1.34)	Loss   1.35 (  2.16)	Cls Acc 67.6 (46.2)	Domain Acc 95.3 (94.6)
Epoch: [0][ 250/1000]	Time  0.50 ( 1.46)	Data  0.39 ( 1.34)	Loss   2.37 (  2.04)	Cls Acc 66.4 (50.4)	Domain Acc 68.8 (93.5)
Epoch: [0][ 300/1000]	Time  2.80 ( 1.46)	Data  2.69 ( 1.35)	Loss   1.25 (  1.97)	Cls Acc 78.1 (53.9)	Domain Acc 84.8 (91.3)
Epoch: [0][ 350/1000]	Time  0.50 ( 1.46)	Data  0.39 ( 1.34)	Loss   1.34 (  1.91)	Cls Acc 78.5 (56.9)	Domain Acc 79.3 (89.1)
Epoch: [0][ 400/1000]	Time  0.50 ( 1.46)	Data  0.39 ( 1.35)	Loss   1.47 (  1.89)	Cls Acc 71.1 (59.3)	Domain Acc 77.9 (86.4)
Epoch: [0][ 450/1000]	Time  2.84 ( 1.46)	Data  2.73 ( 1.35)	Loss   1.13 (  1.84)	Cls Acc 84.0 (61.7)	Domain Acc 77.1 (84.7)
Epoch: [0][ 500/1000]	Time  0.50 ( 1.46)	Data  0.39 ( 1.35)	Loss   1.20 (  1.78)	Cls Acc 83.6 (63.8)	Domain Acc 70.5 (83.1)
Epoch: [0][ 550/1000]	Time  2.27 ( 1.46)	Data  2.15 ( 1.35)	Loss   1.58 (  1.78)	Cls Acc 79.7 (65.4)	Domain Acc 66.0 (80.6)
Epoch: [0][ 600/1000]	Time  2.72 ( 1.46)	Data  2.61 ( 1.35)	Loss   1.25 (  1.76)	Cls Acc 89.1 (66.9)	Domain Acc 61.3 (79.3)
Epoch: [0][ 650/1000]	Time  0.51 ( 1.46)	Data  0.40 ( 1.35)	Loss   0.93 (  1.71)	Cls Acc 92.2 (68.6)	Domain Acc 72.7 (78.2)
Epoch: [0][ 700/1000]	Time  0.49 ( 1.46)	Data  0.37 ( 1.35)	Loss   1.29 (  1.66)	Cls Acc 88.3 (70.2)	Domain Acc 54.3 (77.1)
Epoch: [0][ 750/1000]	Time  3.80 ( 1.46)	Data  3.69 ( 1.35)	Loss   1.42 (  1.64)	Cls Acc 88.3 (71.5)	Domain Acc 48.6 (75.5)
Epoch: [0][ 800/1000]	Time  0.50 ( 1.46)	Data  0.39 ( 1.35)	Loss   1.29 (  1.62)	Cls Acc 90.2 (72.6)	Domain Acc 38.9 (74.0)
Epoch: [0][ 850/1000]	Time  0.50 ( 1.46)	Data  0.39 ( 1.35)	Loss   1.18 (  1.59)	Cls Acc 94.5 (73.9)	Domain Acc 41.2 (72.8)
Epoch: [0][ 900/1000]	Time  2.63 ( 1.46)	Data  2.52 ( 1.35)	Loss   1.09 (  1.55)	Cls Acc 93.0 (75.0)	Domain Acc 53.7 (71.9)
Epoch: [0][ 950/1000]	Time  0.50 ( 1.46)	Data  0.39 ( 1.35)	Loss   1.09 (  1.53)	Cls Acc 94.5 (76.1)	Domain Acc 50.0 (70.8)
